{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# システム統合２（フレーム）\n",
    "それでは、これまでに実装してきたモジュールを統合して音声対話システムを作成してみましょう。\n",
    "\n",
    "- 仕様\n",
    "    - 音声認識：Google（ストリーミング、オリジナルVAD）\n",
    "    - 音声合成：Google\n",
    "    - 言語理解：ルールベース（フレーム）\n",
    "    - 対話管理：フレーム"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要なラブラリを読み込む\n",
    "from __future__ import division\n",
    "\n",
    "import re\n",
    "import sys, os\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import struct\n",
    "\n",
    "import pyaudio\n",
    "from six.moves import queue\n",
    "\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "\n",
    "from google.cloud import speech\n",
    "\n",
    "# 実装したライブラリを読み込む\n",
    "from asr_google_streaming_vad import GoogleStreamingASR, MicrophoneStream\n",
    "from tts_google import GoogleTextToSpeech\n",
    "from dm_frame import DmFrame\n",
    "from slu_rule import SluRule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 音声認識クラスのパラメータ\n",
    "RATE = 16000\n",
    "CHUNK = int(RATE / 10)  # 100ms\n",
    "\n",
    "# 音声合成の初期化\n",
    "tts = GoogleTextToSpeech()\n",
    "\n",
    "# 言語理解の初期化\n",
    "slu_parser = SluRule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "システム： こんにちは。京都レストラン案内です。ご質問をどうぞ。\n",
      "<<<please speak>>>\n",
      "音声パワー： 36.8[dB] 途中結果: 京都駅で中華料理ユーザ： 京都駅で中華料理\n",
      "[{'intent': None, 'slot_name': 'place', 'slot_value': '京都'}, {'intent': None, 'slot_name': 'genre', 'slot_value': '中華'}]\n",
      "システム： 地域は京都で、ジャンルは中華ですね。検索します。\n"
     ]
    }
   ],
   "source": [
    "# 対話管理の初期化\n",
    "dm = DmFrame()\n",
    "\n",
    "# 初期状態の発話\n",
    "system_utterance = dm.utterance_start\n",
    "tts.generate(system_utterance)\n",
    "print(\"システム： \" + system_utterance)\n",
    "tts.play()\n",
    "\n",
    "# 全てのフレームが埋まるまで対話を続ける\n",
    "while(dm.current_frame_filled == False):\n",
    "\n",
    "    # 音声認識入力を得る\t\n",
    "    micStream = MicrophoneStream(RATE, CHUNK)\n",
    "    asrStream = GoogleStreamingASR(RATE, micStream)\n",
    "    print('<<<please speak>>>')\n",
    "    result_asr = asrStream.get_asr_result()\n",
    "\n",
    "    if hasattr(result_asr, 'alternatives') == False:\n",
    "        print('Invalid ASR input')\n",
    "        continue\n",
    "\n",
    "    result_asr_utterance = result_asr.alternatives[0].transcript\n",
    "    print(\"ユーザ： \" + result_asr_utterance)\n",
    "    \n",
    "    # 言語理解\n",
    "    result_slu = slu_parser.parse_frame(result_asr_utterance)\n",
    "    print(result_slu)\n",
    "    \n",
    "    # 対話管理へ入力\n",
    "    system_utterance = dm.enter(result_slu)\n",
    "    tts.generate(system_utterance)\n",
    "    print(\"システム： \" + system_utterance)\n",
    "    tts.play()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
