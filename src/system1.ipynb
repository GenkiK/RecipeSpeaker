{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# システム統合１（有限オートマトン）\n",
    "それでは、これまでに実装してきたモジュールを統合して音声対話システムを作成してみましょう。\n",
    "\n",
    "- 仕様\n",
    "    - 音声認識：Google（ストリーミング、オリジナルVAD）\n",
    "    - 音声合成：Google\n",
    "    - 言語理解：ルールベース（フレーム）\n",
    "    - 対話管理：有限オートマトン"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要なラブラリを読み込む\n",
    "# from __future__ import division\n",
    "\n",
    "# import re\n",
    "# import sys, os\n",
    "\n",
    "# import numpy as np\n",
    "# import math\n",
    "# import struct\n",
    "\n",
    "# import pyaudio\n",
    "# from six.moves import queue\n",
    "\n",
    "# from pydub import AudioSegment\n",
    "# from pydub.playback import play\n",
    "\n",
    "# # Google音声認識を使用するためのライブラリ\n",
    "# from google.cloud import speech\n",
    "\n",
    "# 実装したライブラリを読み込む\n",
    "#from asr_google_streaming import GoogleStreamingASR, MicrophoneStream       # VADなし\n",
    "from asr_google_streaming_vad import GoogleStreamingASR, MicrophoneStream   # VADあり\n",
    "from tts_google import GoogleTextToSpeech\n",
    "from dm_fst import DmFst\n",
    "from slu_rule import SluRule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 音声認識クラスのパラメータ\n",
    "RATE = 16000\n",
    "CHUNK = int(RATE / 10)  # 100ms\n",
    "\n",
    "# 音声合成の初期化\n",
    "tts = GoogleTextToSpeech()\n",
    "\n",
    "# 言語理解の初期化\n",
    "slu_parser = SluRule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "システム： こんにちは。京都レストラン案内です。どの地域のレストランをお探しですか。\n",
      "<<<please speak>>>\n",
      "音声パワー： 48.6[dB] 途中結果: 百万遍でお願いしますユーザ： 百万遍でお願いします\n",
      "[{'intent': None, 'slot_name': 'place', 'slot_value': '百万遍'}]\n",
      "システム： どのような料理がお好みですか。\n",
      "\n",
      "<<<please speak>>>\n",
      "音声パワー： 46.5[dB] ユーザ： 中華料理が食べたいい\n",
      "[{'intent': None, 'slot_name': 'genre', 'slot_value': '中華'}]\n",
      "システム： ご予算はおいくらぐらいですか。\n",
      "\n",
      "<<<please speak>>>\n",
      "音声パワー： 47.5[dB] ユーザ： 2000円以下でお願いしますす\n",
      "[{'intent': None, 'slot_name': 'budget', 'slot_value': '2000円'}]\n",
      "システム： 検索します。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 対話管理の初期化\n",
    "dm = DmFst()\n",
    "\n",
    "# 初期状態の発話\n",
    "system_utterance = dm.get_system_utterance()\n",
    "tts.generate(system_utterance)\n",
    "print(\"システム： \" + system_utterance)\n",
    "tts.play()\n",
    "\n",
    "# 対話が終了状態に移るまで対話を続ける\n",
    "while(dm.end == False):\n",
    "\n",
    "    # 音声認識入力を得る\t\n",
    "    micStream = MicrophoneStream(RATE, CHUNK)\n",
    "    asrStream = GoogleStreamingASR(RATE, micStream)\n",
    "    print('<<<please speak>>>')\n",
    "    result_asr = asrStream.get_asr_result()\n",
    "\n",
    "    if hasattr(result_asr, 'alternatives') == False:\n",
    "        print('Invalid ASR input')\n",
    "        continue\n",
    "\n",
    "    result_asr_utterance = result_asr.alternatives[0].transcript\n",
    "    print(\"ユーザ： \" + result_asr_utterance)\n",
    "    \n",
    "    # 言語理解\n",
    "    result_slu = slu_parser.parse_frame(result_asr_utterance)\n",
    "    print(result_slu)\n",
    "    \n",
    "    # 対話管理へ入力\n",
    "    system_utterance = dm.enter(result_slu)\n",
    "    tts.generate(system_utterance)\n",
    "    print(\"システム： \" + system_utterance)\n",
    "    tts.play()\n",
    "    \n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
